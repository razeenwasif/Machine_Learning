





# Set-up code
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt

# Jupyter magic for inline figures
%matplotlib inline 

mpl.rcParams['image.cmap'] = 'Accent' # Changing the default colour-scheme for readability





def plot_2d_clusters(data, labels):
    """Plot a set of 2-d datapoints (data) with colours according to the label."""
    
    plt.scatter(data[:, 0], data[:, 1], c=labels)


# Clustering Visualisation Test Code

from sklearn.datasets import make_blobs # Function for generating Gaussian clusters

centers = 5 # Number of clusters.
n_samples = 300 # Number of datapoints to generate

random_state = 42 # Random seed
data, labels = make_blobs(centers=centers, n_samples=n_samples, random_state=random_state)

plt.figure(figsize=(6, 12))

plt.subplot(211)
plt.title("make_blobs 5-cluster example")
plot_2d_clusters(data, labels)

# Generate the dataset we'll use for the rest of this lab.
centers = [(-2, -2), (2, 2)] # We can also specify centroid coordinates
data, labels = make_blobs(centers=centers, n_samples=n_samples, random_state=random_state)

plt.subplot(212)
plt.title("2-cluster dataset")
plot_2d_clusters(data, labels)

plt.plot()
None # Don't display output








from sklearn.cluster import KMeans 
def k_means_clustering(data, k=2): #The default k=2 only because of convenience in this exercise. Is this always true?
    """Cluster a dataset using the K-means clustering algorithm.
    
    Note that you need to return an array of integers (either 0 or 1) for each datapoint representing which
    of the two clusters they belong to. Remember that labels are arbritrary (i.e. you can swap all 0s and 1s)."""
    kmeans = KMeans(n_clusters=k).fit(data) 
    return kmeans.labels_ 


# K-Means Test Code

pred_labels = k_means_clustering(data)

plt.figure(figsize=(12, 6))

plt.subplot(121)
plt.title("K-Means Clustering Predicted Labels")
plot_2d_clusters(data, pred_labels)

plt.subplot(122)
plt.title("True Labels")
plot_2d_clusters(data, labels)


plt.plot()
None # Don't display output





def accuracy(pred_labels, true_labels):
    """Compute the accuracy of the predicated labels vs the true labels.
    
    Remember that the labels may be inverted (i.e. the original 0s may now be the 1s).
    You should use whichever set of labellings have the best accuracy. """
    
    acc = (true_labels == pred_labels).sum() / pred_labels.shape[0]
    return max(acc, 1-acc)

def sum_of_squares(data):
    """Find the sum total disance of the datapoints from the centroid."""
    centroid = data.mean(axis=0)
    distances = data - centroid
    return np.sum(distances**2)

def loss(data, labels):
    """Compute the loss of the dataset according to the predicted labels.
    
    Hint: it may be useful to use a helper function to compute the loss for each centroid."""
    bool_labels = labels == 1
    pos_data = data[bool_labels]
    neg_data = data[~bool_labels]
    return (sum_of_squares(pos_data) + sum_of_squares(neg_data))
    
    


from time import process_time

# Clustering Comparison Test Code
centers = [(2, 2), (4,4)]
data, labels = make_blobs(centers=centers, n_samples=n_samples, random_state=random_state)

before_time = process_time()
k_means_labels = k_means_clustering(data)
duration = process_time() - before_time
print(f"K-Means Clustering Runtime: {duration * 1000:.1f}ms")
print()

#Print statistics
print(f"K-Means Clustering Accuracy: {accuracy(k_means_labels, labels) * 100:.2f}%")
print()
print(f"Average Loss (True): {loss(data, labels)/n_samples:.2f}")
print(f"Average Loss (K_Means): {loss(data, k_means_labels)/n_samples:.2f}")

plt.figure(figsize=(18, 6))

plt.subplot(121)
plt.title("True Labels")
plot_2d_clusters(data, labels)

plt.subplot(122)
plt.title("K-Means Clustering Predicted Labels")
plot_2d_clusters(data, k_means_labels)

plt.plot()
None # Don't display output


# Choice of k
# Feel free to change the number of centers. We can start with 4
centers = 4
data, labels = make_blobs(centers=centers, n_samples=n_samples, random_state=random_state)

print("         k","  accuracy","      loss")
for k in [2,4,6,8,10]:
    """What accuracy and loss would you get by calling k-means on the sane data for these values of k?"""
    """Will the implementations for loss and accuracy still work? Discuss."""
    k_means_labels = None    
    acc = 0 #Compute
    ls = 0  #Compute
    print('{:10}'.format(k), '{:10.3f}'.format(acc), '{:10.3f}'.format(ls))

    """What do the clusters look like?"""

    plt.figure(figsize=(9, 6))
    plt.title("K-Means k="+str(k))
    plot_2d_clusters(data, k_means_labels)

None # Don't display output






